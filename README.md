# AI4Med

| No. | Name | Paper Title | Pub |Imaging | Based | Main Contribution |  Abstract | Code |
|----:|--------|------------|------|------|------|-------------------|-----------|----------|
| 1   | [SLATER](https://arxiv.org/pdf/2105.08059) | Unsupervised MRI Reconstruction via Zero-Shot Learned Adversarial Transformers | TMI(2022) | MRI| Volume| Unsupervised MRI Reconstruction via Zero-Shot Learned Adversarial Transformers  | <details><summary>Click</summary> Supervised reconstruction models are characteristically trained on matched pairs of undersampled and fully-sampled data to capture an MRI prior, along with supervision regarding the imaging operator to enforce data consistency. To reduce supervision requirements, the recent deep image prior framework instead conjoins untrained MRI priors with the imaging operator during inference. Yet, canonical convolutional architectures are suboptimal in capturing long-range relationships, and priors based on randomly initialized networks may yield suboptimal performance. To address these limitations, here we introduce a novel unsupervised MRI reconstruction method based on zero-Shot Learned Adversarial TransformERs (SLATER). SLATER embodies a deep adversarial network with cross-attention transformers to map noise and latent variables onto coil-combined MR images. During pre-training, this unconditional network learns a high-quality MRI prior in an unsupervised generative modeling task. During inference, a zero-shot reconstruction is then performed by incorporating the imaging operator and optimizing the prior to maximize consistency to undersampled data. Comprehensive experiments on brain MRI datasets clearly demonstrate the superior performance of SLATER against state-of-the-art unsupervised methods. </details> | [üîó](https://github.com/icon-lab/SLATER)
| 2   | [DEER](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9239986) | Deep Efficient End-to-End Reconstruction(DEER) Network for Few-View Breast CT Image Reconstruction | IEEE Access(2020) | CT | Volume | Deep efficient end-to-end reconstruction (DEER)network for few-view breast CT image reconstruction   | <details><summary>Click</summary> Breast CT provides image volumes with isotropic resolution in high contrast, enabling detection of small calcification (down to a few hundred microns in size) and subtle density differences. Since breast is sensitive to x-ray radiation, dose reduction of breast CT is an important topic, and for this purpose, few-view scanning is a main approach. In this article, we propose a Deep Efficient End-to-end Reconstruction (DEER) network for few-view breast CT image reconstruction. The major merits of our network include high dose efficiency, excellent image quality, and low model complexity. By the design, the proposed network can learn the reconstruction process with as few as (9(N) parameters, where N is the side length of an image to be reconstructed, which represents orders of magnitude improvements relative to the state-of-the-art deeplearning-based reconstruction methods that map raw data to tomographic images directly. Also, validated on a cone-beam breast CT dataset prepared by Koning Corporation on a commercial scanner, our method demonstrates a competitive performance over the state-of-the-art reconstruction networks in terms of image quality. The source code of this paper is available at: https://github.com/HuidongXie/DEER. </details> | [üîó](https://github.com/HuidongXie/DEER)
| 3   | [C¬≤RV](https://openaccess.thecvf.com/content/CVPR2024/papers/Lin_C2RV_Cross-Regional_and_Cross-View_Learning_for_Sparse-View_CBCT_Reconstruction_CVPR_2024_paper.pdf) | C^ 2RV: Cross-Regional and Cross-View Learning for Sparse-View CBCT Reconstruction | CVPR(2024) | CT | Volume|Explicit multi-scale volumetric representations are utilized to enable cross - regional learning in the 3D space. The scale - view cross - attention module is introduced to adaptively aggregate multi - scale and multi - view features   | <details><summary>Click</summary> Cone beam computed tomography (CBCT) is an important imaging technology widely used in medical scenarios such as diagnosis and preoperative planning. Using fewer projection views to reconstruct CT also known as sparse-view reconstruction can reduce ionizing radiation and further benefit interventional radiology. Compared with sparse-view reconstruction for traditional parallel/fan-beam CT CBCT reconstruction is more challenging due to the increased dimensionality caused by the measurement process based on cone-shaped X-ray beams. As a 2D-to-3D reconstruction problem although implicit neural representations have been introduced to enable efficient training only local features are considered and different views are processed equally in previous works resulting in spatial inconsistency and poor performance on complicated anatomies. To this end we propose C^2RV by leveraging explicit multi-scale volumetric representations to enable cross-regional learning in the 3D space. Additionally the scale-view cross-attention module is introduced to adaptively aggregate multi-scale and multi-view features. Extensive experiments demonstrate that our C^2RV achieves consistent and significant improvement over previous state-of-the-art methods on datasets with diverse anatomy. Code is available at https://github.com/xmed-lab/C2RV-CBCT. </details> | [üîó](https://github.com/xmed-lab/C2RV-CBCT)
| 4 | [extended-MedNeRF](https://www.biorxiv.org/content/10.1101/2023.04.24.538160v1.full.pdf) | 3D reconstructions of brain from MRI scans using neural radiance fields | ICAISC (2023) |MRI | NRF | a neural radiance field-based approach for reconstructing 3D projections from 2D MRI slices | <details><summary>Click</summary>The advent of 3D Magnetic Resonance Imaging (MRI) has revolutionized medical imaging and diagnostic capabilities, allowing for more precise diagnosis, treatment planning, and improved patient outcomes. 3D MRI imaging enables the creation of detailed 3D reconstructions of anatomical structures that can be used for visualization, analysis, and surgical planning. However, these reconstructions often require many scan acquisitions, demanding a long session to use the machine and requiring the patient to remain still, with consequent possible motion artifacts. The development of neural radiance fields (NeRF) technology has shown promising results in generating highly accurate 3D reconstructions of MRI images with less user input. Our approach is based on neural radiance fields to reconstruct 3D projections from 2D slices of MRI scans. We do this by using 3D convolutional neural networks to address challenges posed by variable slice thickness; incorporating multiple MRI modalities to ensure robustness and extracting the shape and volumetric depth of both surface and internal anatomical structures with slice interpolation. This approach provides more comprehensive and robust 3D reconstructions of both surface and internal anatomical structures and has significant potential for clinical applications, allowing medical professionals to better visualize and analyze anatomical structures with less available data, potentially reducing times and motion-related issues. </details>  | [‚ùå] 
| 5 | [NAF](https://arxiv.org/pdf/2209.14540) | Neural Attenuation Fields for Sparse-View  CBCT Reconstruction | MICCAI (2022) |CT  | NRF | a self-supervised solution for sparse-view CBCT reconstruction without external training data | <details><summary>Click</summary>This paper proposes a novel and fast self-supervised solution for sparse-view CBCT reconstruction (Cone Beam Computed Tomography) that requires no external training data. Specifically, the desired attenuation coefficients are represented as a continuous function of 3D spatial coordinates, parameterized by a fully-connected deep neural network. We synthesize projections discretely and train the network by minimizing the error between real and synthesized projections. A learning-based encoder entailing hash coding is adopted to help the network capture high-frequency details. This encoder outperforms the commonly used frequency-domain encoder in terms of having higher performance and efficiency, because it exploits the smoothness and sparsity of human organs. Experiments have been conducted on both human organ and phantom datasets. The proposed method achieves state-of-the-art accuracy and spends reasonably short computation time. </details>  | [üîó](https://github.com/Ruyi-Zha/naf_cbct) 
‚ùå 
